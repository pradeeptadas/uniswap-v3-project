{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7dc235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from uniswapv3_simulator.pool import Uniswapv3Pool\n",
    "from uniswapv3_simulator.optimization.environments import OneStepEnvironment, ScaleWrapper\n",
    "from uniswapv3_simulator.optimization.ddpg.ddpg import (\n",
    "    DDPG,\n",
    "    DDPGTrainer,\n",
    "    DeepActorModel,\n",
    "    TrainArgs\n",
    ")\n",
    "from uniswapv3_simulator.optimization.ddpg.exploration_noise import GaussianProcess\n",
    "from uniswapv3_simulator.optimization.ddpg.schedulers import ExponentialScheduler\n",
    "\n",
    "timestamp = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    filename=f'./logs/rl_test_{timestamp}.log'\n",
    ")\n",
    "logging.getLogger('optimization').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a012e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "seed_seq = np.random.SeedSequence(entropy=SEED)\n",
    "seeds = seed_seq.generate_state(8)\n",
    "\n",
    "init_price = 100\n",
    "liquidity_bins = [80, 85, 90, 95, 100, 105, 110, 115, 120]\n",
    "\n",
    "# fees = stats.uniform(1e-4, 0.01 - 1e-4)\n",
    "# mu = stats.uniform(-0.05, 0.1)\n",
    "# sigma = stats.uniform(1e-4, 0.1 - 1e-4) \n",
    "# alpha = stats.randint(1, 100 + 1)\n",
    "# beta = stats.randint(100, 1000 + 1)\n",
    "\n",
    "fees = stats.uniform(0.01, 0.0)\n",
    "mu = stats.uniform(0.00, 0.0)\n",
    "sigma = stats.uniform(1e-4, 0.1 - 1e-4)  # vary sigma\n",
    "alpha = stats.randint(1, 100 + 1)  # vary alpha \n",
    "beta = stats.randint(500, 500 + 1)\n",
    "\n",
    "fees.random_state = seeds[0]\n",
    "mu.random_state = seeds[1]\n",
    "sigma.random_state = seeds[2]\n",
    "alpha.random_state = seeds[3]\n",
    "beta.random_state = seeds[4]\n",
    "\n",
    "n_sims_per_step = 500\n",
    "n_jobs = int(mp.cpu_count() / 1) - 1\n",
    "\n",
    "env = OneStepEnvironment(\n",
    "    init_price, liquidity_bins,\n",
    "    fees, mu, sigma, alpha, beta,\n",
    "    n_sims_per_step=n_sims_per_step, \n",
    "    n_jobs=n_jobs, seed=seeds[5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4d2aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Variables\n",
      "fees:  mean=nan, std=nan\n",
      "mu:    mean=nan, std=nan\n",
      "sigma: mean=nan, std=nan\n",
      "alpha: mean=50.50, std=28.87\n",
      "beta:  mean=500.00, std=0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pspalding/opt/anaconda3/envs/rl_env/lib/python3.9/site-packages/scipy/stats/_discrete_distns.py:1035: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  g2 = -6.0/5.0 * (d*d + 1.0) / (d*d - 1.0)\n"
     ]
    }
   ],
   "source": [
    "print('Random Variables')\n",
    "print(f'fees:  mean={fees.mean():,.4f}, std={fees.std():,.4f}')\n",
    "print(f'mu:    mean={mu.mean():,.4f}, std={mu.std():,.4f}')\n",
    "print(f'sigma: mean={sigma.mean():,.4f}, std={sigma.std():,.4f}')\n",
    "print(f'alpha: mean={alpha.mean():,.2f}, std={alpha.std():,.2f}')\n",
    "print(f'beta:  mean={beta.mean():,.2f}, std={beta.std():,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1ce699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_scale_fn(obs):\n",
    "    obs = obs[[3]]\n",
    "    mu = np.array([50.50])\n",
    "    sigma = np.array([28.87])\n",
    "    # mu =    np.array([0.0051, 0.0000, 0.0501, 50.50, 550.00])\n",
    "    # sigma = np.array([0.0029, 0.0289, 0.0288, 28.87, 260.10])\n",
    "    \n",
    "    return (obs - mu) / sigma\n",
    "\n",
    "def action_scale_fn(action):\n",
    "    return action * 1e+5\n",
    "\n",
    "def reward_scale_fn(reward):\n",
    "    return reward * 1e+2\n",
    "\n",
    "env = ScaleWrapper(env, obs_scale_fn, action_scale_fn, reward_scale_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c90fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seeds[6])\n",
    "action_size = len(liquidity_bins) - 1\n",
    "model = DeepActorModel(1, action_size, (128, 64), (128, 64))\n",
    "agent = DDPG(\n",
    "    model=model,\n",
    "    gamma=0.99,\n",
    "    tau=1e-3,\n",
    "    optimizer=optim.Adam,\n",
    "    actor_optimizer_kwargs={\n",
    "        'lr': 1e-4,\n",
    "        'weight_decay': 1e-5\n",
    "    },\n",
    "    critic_optimizer_kwargs={\n",
    "        'lr': 1e-3,\n",
    "        'weight_decay': 1e-5\n",
    "    },\n",
    "    clip_gradients=10.0\n",
    ")\n",
    "train_args = TrainArgs(\n",
    "    train_steps=5000,\n",
    "    batch_size=64, \n",
    "    memory_size=100000,\n",
    "    exploration_noise=GaussianProcess,\n",
    "    noise_kwargs={\n",
    "        'size': (action_size, ), \n",
    "        'std': ExponentialScheduler(0.2, 0.05, 0.9997)\n",
    "    },\n",
    "    update_start=50,\n",
    "    update_freq=2,\n",
    "    clip_actions=(1e-6, np.inf),\n",
    "    seed=seeds[7]\n",
    ")\n",
    "trainer = DDPGTrainer(agent, env, train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f60c365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepActorModel(\n",
       "  (critic_layers): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (actor_layers): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e791c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pspalding/Desktop/Phil/MFE/Courses/AFP/uniswap-v3-project/uniswapv3_simulator/optimization/traders.py:66: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return (-alpha + np.sqrt((alpha + beta * q0) ** 2 + 2 * beta * dy)) / beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 2.52 s, total: 1min 25s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rewards = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c39f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL Environment",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
